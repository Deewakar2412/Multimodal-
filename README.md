# 🧠 AI-Powered Multimodal Conversational Intelligence System

This project is a practical implementation of a multimodal chatbot using **Google's Gemini 2.0 Flash model**, capable of understanding and generating responses from **text, image, or both**.

---

## 🚀 Features

- 🔤 Accepts text input
- 🖼️ Accepts image input (with upload interface)
- 🧾 Combines both for context-rich queries
- 📸 Displays image preview after upload
- 🤖 Generates smart responses using Gemini 2.0 Flash
- 📡 Built for Google Colab (interactive notebook)

---

## 🧰 Technologies Used

- Python
- [Google Generative AI Python SDK](https://pypi.org/project/google-generativeai/)
- PIL (Pillow) for image handling
- IPyWidgets for interactive upload
- Google Colab (recommended)

---

## 📸 Demo

https://colab.research.google.com/your-colab-link-here

---

## 🛠️ How to Run

1. **Clone this repository**
   ```bash
   git clone https://github.com/your-username/your-repo-name.git
2.Open in Google Colab
3.Open the .ipynb notebook file in Google Colab for interactive usage.
pip install google-generativeai Pillow
4.Install dependencies Colab will automatically handle most dependencies. To install manually:
Run the notebook and follow the prompts

Choose input type (text / image / both)

If image is selected, upload it using the UI

Get the response from Gemini AI

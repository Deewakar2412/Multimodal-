# ğŸ§  AI-Powered Multimodal Conversational Intelligence System

This project is a practical implementation of a multimodal chatbot using **Google's Gemini 2.0 Flash model**, capable of understanding and generating responses from **text, image, or both**.

---

## ğŸš€ Features

- ğŸ”¤ Accepts text input
- ğŸ–¼ï¸ Accepts image input (with upload interface)
- ğŸ§¾ Combines both for context-rich queries
- ğŸ“¸ Displays image preview after upload
- ğŸ¤– Generates smart responses using Gemini 2.0 Flash
- ğŸ“¡ Built for Google Colab (interactive notebook)

---

## ğŸ§° Technologies Used

- Python
- [Google Generative AI Python SDK](https://pypi.org/project/google-generativeai/)
- PIL (Pillow) for image handling
- IPyWidgets for interactive upload
- Google Colab (recommended)

---

## ğŸ“¸ Demo

https://colab.research.google.com/your-colab-link-here

---

## ğŸ› ï¸ How to Run

1. **Clone this repository**
   ```bash
   git clone https://github.com/your-username/your-repo-name.git
2.Open in Google Colab
3.Open the .ipynb notebook file in Google Colab for interactive usage.
pip install google-generativeai Pillow
4.Install dependencies Colab will automatically handle most dependencies. To install manually:
Run the notebook and follow the prompts

Choose input type (text / image / both)

If image is selected, upload it using the UI

Get the response from Gemini AI
